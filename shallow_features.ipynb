{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embeddings', 'train.csv', 'test.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "base_dir = \"./input\"\n",
    "print(os.listdir(base_dir))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e31d6e126881ee56a1de3efe02fcf309e900ef00"
   },
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 70 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "522d9790478f62193ea5c315372a2ab9cbe9b27f"
   },
   "source": [
    "**Load packages and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, GRU, LSTM\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import Callback\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't hog GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e18ed4339c33036cc39ded79c58901da9fbe0aeb"
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, \" \" + punct + \" \")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metadata(df):\n",
    "    # Pure statistical features\n",
    "    df['length'] = df['question_text'].progress_apply(lambda x : len(x))\n",
    "    df['capitals'] = df['question_text'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['caps_vs_length'] = df.progress_apply(lambda row: float(row['capitals'])/float(row['length']),axis=1)\n",
    "    df['num_math'] = df['question_text'].progress_apply(lambda comment: sum(comment.count(w) for w in ('+','-','*','/','%',')','(','^',')','=','<','>')))\n",
    "    df['num_exclamation_marks'] = df['question_text'].progress_apply(lambda comment: comment.count('!'))\n",
    "    df['num_question_marks'] = df['question_text'].progress_apply(lambda comment: comment.count('?'))\n",
    "    df['num_punctuation'] = df['question_text'].progress_apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "    df['num_symbols'] = df['question_text'].progress_apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n",
    "    df['num_words'] = df['question_text'].progress_apply(lambda comment: len(comment.split()))\n",
    "    df['num_unique_words'] = df['question_text'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']\n",
    "    df['num_smilies'] = df['question_text'].progress_apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n",
    "    df['num_sad'] = df['question_text'].progress_apply(lambda comment: sum(comment.count(w) for w in (':-<', ':()', ';-()', ';(')))\n",
    "    df['num_chars'] =    df['question_text'].progress_apply(len)\n",
    "\n",
    "    # More Handy Features\n",
    "    df[\"count_words_title\"] = df[\"question_text\"].progress_apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "    df[\"mean_word_len\"] = df[\"question_text\"].progress_apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    df['punct_percent']= df['num_punctuation']*100/df['num_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5cdc95950037613c690c49b27930ae0f59eb23c3"
   },
   "outputs": [],
   "source": [
    "def load_and_prec():\n",
    "    train_df = pd.read_csv(base_dir + \"/train.csv\")\n",
    "    test_df = pd.read_csv(base_dir + \"/test.csv\")\n",
    "    \n",
    "    # Generate metadata\n",
    "    gen_metadata(test_df)\n",
    "    gen_metadata(train_df)\n",
    "        \n",
    "    # Concatenate all meta-features into one list of features\n",
    "    metadata_keys = ['length', 'capitals', 'caps_vs_length', 'num_math',\n",
    "                     'num_exclamation_marks', 'num_question_marks', 'num_punctuation',\n",
    "                     'num_symbols', 'num_words', 'num_unique_words', 'words_vs_unique',\n",
    "                     'num_smilies', 'num_sad', 'num_chars', 'count_words_title',\n",
    "                     'mean_word_len', 'punct_percent']\n",
    "    test_meta  = create_metadata_feature(test_df, metadata_keys)\n",
    "    train_meta = create_metadata_feature(train_df, metadata_keys)\n",
    "    \n",
    "    print(\"Train shape : \",train_meta.shape)\n",
    "    print(\"Test shape : \",test_meta.shape)\n",
    "\n",
    "    ## Get the target values\n",
    "    train_y = train_df['target'].values\n",
    "    \n",
    "    return train_meta, test_meta, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_feature(df, keys):\n",
    "    data = []\n",
    "    for key in tqdm(keys):\n",
    "        data.append(df[key].values)\n",
    "    data = np.array(data).T\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba1893c267a1e7536bbf720636647d85c7e349c"
   },
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56370/56370 [00:00<00:00, 358040.19it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 91037.17it/s]\n",
      "100%|██████████| 56370/56370 [00:01<00:00, 31328.05it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 136740.01it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 380065.90it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 431785.74it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 182834.87it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 215323.07it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 238330.50it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 147945.80it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 243183.45it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 296506.65it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 742174.09it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 261795.68it/s]\n",
      "100%|██████████| 56370/56370 [00:00<00:00, 60668.07it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 526663.61it/s]\n",
      "100%|██████████| 1306122/1306122 [00:13<00:00, 99915.57it/s] \n",
      "100%|██████████| 1306122/1306122 [00:42<00:00, 30476.68it/s]\n",
      "100%|██████████| 1306122/1306122 [00:09<00:00, 143185.55it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 448337.21it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 549590.97it/s]\n",
      "100%|██████████| 1306122/1306122 [00:04<00:00, 302645.95it/s]\n",
      "100%|██████████| 1306122/1306122 [00:04<00:00, 285440.48it/s]\n",
      "100%|██████████| 1306122/1306122 [00:04<00:00, 303574.03it/s]\n",
      "100%|██████████| 1306122/1306122 [00:07<00:00, 176238.89it/s]\n",
      "100%|██████████| 1306122/1306122 [00:04<00:00, 289964.51it/s]\n",
      "100%|██████████| 1306122/1306122 [00:05<00:00, 249885.44it/s]\n",
      "100%|██████████| 1306122/1306122 [00:02<00:00, 549626.92it/s]\n",
      "100%|██████████| 1306122/1306122 [00:07<00:00, 166529.28it/s]\n",
      "100%|██████████| 1306122/1306122 [00:33<00:00, 39454.21it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 8881.81it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 6957.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 17)\n",
      "Test shape :  (56370, 17)\n",
      "Time taken to process data : 156.06918740272522\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "train_X, test_X, train_y = load_and_prec()\n",
    "print(\"Time taken to process data :\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F-1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80810\n",
      "1225312\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_y==1))\n",
    "print(np.sum(train_y==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = SVC(gamma='auto', probability=True)\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/paragag/persona/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|██████████| 100/100 [00:33<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.04333943562652594, 0.043532329833120956, 0.058881513011283915, 0.06618023043972161, 0.06865876270840207, 0.07947090237264433, 0.08226520237133385, 0.08436348728227262, 0.08522481830682388, 0.08538553417171467, 0.08598296022848236, 0.0954586974393326, 0.0954586974393326, 0.096052732452182, 0.096052732452182, 0.096052732452182, 0.09788632084399372, 0.09788632084399372, 0.09788632084399372, 0.10526851218419003, 0.10526851218419003, 0.10526851218419003, 0.1091482350536983, 0.1091482350536983, 0.1091482350536983, 0.1091482350536983, 0.1091482350536983, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.1111796633768846, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.11644067246644338, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436, 0.1164871295695436]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1s = []\n",
    "for threshold in tqdm(range(int(1e2))):\n",
    "    f1s.append(f1_score(train_y, (clf.predict_proba(train_X)[:,1] < threshold * 1e-2).astype(int)))\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a2e5b9353012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test_y = clf.predict_proba(test_X)[:,1]\n",
    "print(np.sum(preds > 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.3\n",
    "pred_test_y = (pred_test_y > best_threshold).astype(int)\n",
    "test_df = pd.read_csv(base_dir +\"/test.csv\", usecols=[\"qid\"])\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
